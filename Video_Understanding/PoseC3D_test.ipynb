{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pose_prediction\\\\data_agent\\\\Video_Understanding\\\\mmaction2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "Performing Human Detection for each frame\n",
      "[                                                  ] 0/10, elapsed: 0s, ETA:02/19 16:18:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "02/19 16:18:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 0.3 task/s, elapsed: 30s, ETA:     0s\n",
      "\n",
      "Easy Example\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\" to C:\\Users\\zesky/.cache\\torch\\hub\\checkpoints\\hrnet_w32_coco_256x192-c78dce93_20200708.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Human Pose Estimation for each frame\n",
      "[                                                  ] 0/10, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmpose\\apis\\inference.py:121: UserWarning: Can not load dataset_meta from the checkpoint or the model config. Use COCO metainfo by default.\n",
      "  warnings.warn('Can not load dataset_meta from the checkpoint or the '\n",
      "d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmpose\\datasets\\datasets\\utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco.py\" does not exist. A matched config file \"d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmpose\\.mim\\configs\\_base_\\datasets\\coco.py\" will be used instead.\n",
      "  warnings.warn(\n",
      "d:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmcv\\transforms\\loading.py:69: DeprecationWarning: \"file_client_args\" will be deprecated in future. Please use \"backend_args\" instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 2.9 task/s, elapsed: 3s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "video_input = r\"D:\\pose_prediction\\data_agent\\data\\video_split\\S001C001P001R001A001_rgb.mp4\"\n",
    "pkl_output = r\"D:\\pose_prediction\\data_agent\\data\\video_split\\A1\\S001C001P001R001A001.pkl\"\n",
    "device = \"cpu\"\n",
    "\n",
    "%run tools/data/skeleton/ntu_pose_extraction.py \"$video_input\" \"$pkl_output\" --device $device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/19 17:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "    CUDA available: False\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1153359205\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.4.1+cpu\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.19.1+cpu\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.6\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1153359205\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "02/19 17:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file = 'data/skeleton/gym_2d.pkl'\n",
      "dataset_type = 'PoseDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "left_kp = [\n",
      "    1,\n",
      "    3,\n",
      "    5,\n",
      "    7,\n",
      "    9,\n",
      "    11,\n",
      "    13,\n",
      "    15,\n",
      "]\n",
      "load_from = 'checkpoints/slowonly_r50_8xb16-u48-240e_gym-keypoint_20220815-da338c58.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_channels=32,\n",
      "        conv1_stride_s=1,\n",
      "        depth=50,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        in_channels=17,\n",
      "        inflate=(\n",
      "            0,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        num_stages=3,\n",
      "        out_indices=(2, ),\n",
      "        pool1_stride_s=1,\n",
      "        pretrained=None,\n",
      "        spatial_strides=(\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        stage_blocks=(\n",
      "            4,\n",
      "            6,\n",
      "            3,\n",
      "        ),\n",
      "        temporal_strides=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "        ),\n",
      "        type='ResNet3dSlowOnly'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        dropout_ratio=0.5,\n",
      "        in_channels=512,\n",
      "        num_classes=99,\n",
      "        spatial_type='avg',\n",
      "        type='I3DHead'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(lr=0.2, momentum=0.9, type='SGD', weight_decay=0.0003))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        T_max=24,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        eta_min=0,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "right_kp = [\n",
      "    2,\n",
      "    4,\n",
      "    6,\n",
      "    8,\n",
      "    10,\n",
      "    12,\n",
      "    14,\n",
      "    16,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/gym_2d.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=48,\n",
      "                num_clips=10,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                double=True,\n",
      "                left_kp=[\n",
      "                    1,\n",
      "                    3,\n",
      "                    5,\n",
      "                    7,\n",
      "                    9,\n",
      "                    11,\n",
      "                    13,\n",
      "                    15,\n",
      "                ],\n",
      "                right_kp=[\n",
      "                    2,\n",
      "                    4,\n",
      "                    6,\n",
      "                    8,\n",
      "                    10,\n",
      "                    12,\n",
      "                    14,\n",
      "                    16,\n",
      "                ],\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        clip_len=48, num_clips=10, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        double=True,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=24, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file='data/skeleton/gym_2d.pkl',\n",
      "            pipeline=[\n",
      "                dict(clip_len=48, type='UniformSampleFrames'),\n",
      "                dict(type='PoseDecode'),\n",
      "                dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "                dict(scale=(\n",
      "                    -1,\n",
      "                    64,\n",
      "                ), type='Resize'),\n",
      "                dict(area_range=(\n",
      "                    0.56,\n",
      "                    1.0,\n",
      "                ), type='RandomResizedCrop'),\n",
      "                dict(keep_ratio=False, scale=(\n",
      "                    56,\n",
      "                    56,\n",
      "                ), type='Resize'),\n",
      "                dict(\n",
      "                    flip_ratio=0.5,\n",
      "                    left_kp=[\n",
      "                        1,\n",
      "                        3,\n",
      "                        5,\n",
      "                        7,\n",
      "                        9,\n",
      "                        11,\n",
      "                        13,\n",
      "                        15,\n",
      "                    ],\n",
      "                    right_kp=[\n",
      "                        2,\n",
      "                        4,\n",
      "                        6,\n",
      "                        8,\n",
      "                        10,\n",
      "                        12,\n",
      "                        14,\n",
      "                        16,\n",
      "                    ],\n",
      "                    type='Flip'),\n",
      "                dict(\n",
      "                    sigma=0.6,\n",
      "                    type='GeneratePoseTarget',\n",
      "                    use_score=True,\n",
      "                    with_kp=True,\n",
      "                    with_limb=False),\n",
      "                dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "                dict(type='PackActionInputs'),\n",
      "            ],\n",
      "            split='train',\n",
      "            type='PoseDataset'),\n",
      "        times=10,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(clip_len=48, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(area_range=(\n",
      "        0.56,\n",
      "        1.0,\n",
      "    ), type='RandomResizedCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        56,\n",
      "        56,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        flip_ratio=0.5,\n",
      "        left_kp=[\n",
      "            1,\n",
      "            3,\n",
      "            5,\n",
      "            7,\n",
      "            9,\n",
      "            11,\n",
      "            13,\n",
      "            15,\n",
      "        ],\n",
      "        right_kp=[\n",
      "            2,\n",
      "            4,\n",
      "            6,\n",
      "            8,\n",
      "            10,\n",
      "            12,\n",
      "            14,\n",
      "            16,\n",
      "        ],\n",
      "        type='Flip'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='data/skeleton/gym_2d.pkl',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                clip_len=48,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='UniformSampleFrames'),\n",
      "            dict(type='PoseDecode'),\n",
      "            dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                64,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=64, type='CenterCrop'),\n",
      "            dict(\n",
      "                sigma=0.6,\n",
      "                type='GeneratePoseTarget',\n",
      "                use_score=True,\n",
      "                with_kp=True,\n",
      "                with_limb=False),\n",
      "            dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        test_mode=True,\n",
      "        type='PoseDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(clip_len=48, num_clips=1, test_mode=True, type='UniformSampleFrames'),\n",
      "    dict(type='PoseDecode'),\n",
      "    dict(allow_imgpad=True, hw_ratio=1.0, type='PoseCompact'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        64,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=64, type='CenterCrop'),\n",
      "    dict(\n",
      "        sigma=0.6,\n",
      "        type='GeneratePoseTarget',\n",
      "        use_score=True,\n",
      "        with_kp=True,\n",
      "        with_limb=False),\n",
      "    dict(input_format='NCTHW_Heatmap', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\slowonly_r50_8xb16-u48-240e_gym-keypoint'\n",
      "\n",
      "02/19 17:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "02/19 17:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\\tools\\test.py:126\u001b[0m\n\u001b[0;32m    122\u001b[0m     runner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\\tools\\test.py:122\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m     runner \u001b[38;5;241m=\u001b[39m RUNNERS\u001b[38;5;241m.\u001b[39mbuild(cfg)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# start testing\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\runner\\runner.py:1816\u001b[0m, in \u001b[0;36mRunner.test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1812\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`self._test_loop` should not be None when calling test \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1813\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod. Please provide `test_dataloader`, `test_cfg` and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1814\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`test_evaluator` arguments when initializing runner.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1816\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_loop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;66;03m# make sure checkpoint-related hooks are triggered after `before_run`\u001b[39;00m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\runner\\runner.py:1604\u001b[0m, in \u001b[0;36mRunner.build_test_loop\u001b[1;34m(self, loop)\u001b[0m\n\u001b[0;32m   1601\u001b[0m loop_cfg \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(loop)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m loop_cfg:\n\u001b[1;32m-> 1604\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[43mLOOPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_evaluator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1611\u001b[0m     loop \u001b[38;5;241m=\u001b[39m TestLoop(\n\u001b[0;32m   1612\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloop_cfg,\n\u001b[0;32m   1613\u001b[0m         runner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1614\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_dataloader,\n\u001b[0;32m   1615\u001b[0m         evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_evaluator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\registry\\registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[1;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\registry\\build_functions.py:123\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[1;34m(cfg, registry, default_args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[0;32m    127\u001b[0m     print_log(\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    131\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    132\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\runner\\loops.py:434\u001b[0m, in \u001b[0;36mTestLoop.__init__\u001b[1;34m(self, runner, dataloader, evaluator, fp16)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    430\u001b[0m              runner,\n\u001b[0;32m    431\u001b[0m              dataloader: Union[DataLoader, Dict],\n\u001b[0;32m    432\u001b[0m              evaluator: Union[Evaluator, Dict, List],\n\u001b[0;32m    433\u001b[0m              fp16: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mbuild_evaluator(evaluator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\runner\\base_loop.py:26\u001b[0m, in \u001b[0;36mBaseLoop.__init__\u001b[1;34m(self, runner, dataloader)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloader, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Determine whether or not different ranks use different seed.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     diff_rank_seed \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39m_randomness_cfg\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_rank_seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m dataloader\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\runner\\runner.py:1370\u001b[0m, in \u001b[0;36mRunner.build_dataloader\u001b[1;34m(dataloader, seed, diff_rank_seed)\u001b[0m\n\u001b[0;32m   1368\u001b[0m dataset_cfg \u001b[38;5;241m=\u001b[39m dataloader_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_cfg, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m-> 1370\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_init\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1372\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mfull_init()\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\registry\\registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[1;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\registry\\build_functions.py:123\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[1;34m(cfg, registry, default_args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[0;32m    127\u001b[0m     print_log(\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    131\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    132\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\\mmaction\\datasets\\pose_dataset.py:56\u001b[0m, in \u001b[0;36mPoseDataset.__init__\u001b[1;34m(self, ann_file, pipeline, split, valid_ratio, box_thr, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m box_thr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m.6\u001b[39m, \u001b[38;5;241m.7\u001b[39m, \u001b[38;5;241m.8\u001b[39m, \u001b[38;5;241m.9\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_ratio \u001b[38;5;241m=\u001b[39m valid_ratio\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\\mmaction\\datasets\\base.py:48\u001b[0m, in \u001b[0;36mBaseActionDataset.__init__\u001b[1;34m(self, ann_file, pipeline, data_prefix, test_mode, multi_class, num_classes, start_index, modality, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_index \u001b[38;5;241m=\u001b[39m start_index\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality \u001b[38;5;241m=\u001b[39m modality\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\dataset\\base_dataset.py:247\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[1;34m(self, ann_file, metainfo, data_root, data_prefix, filter_cfg, indices, serialize_data, pipeline, test_mode, lazy_init, max_refetch)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Full initialize the dataset.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lazy_init:\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction\\lib\\site-packages\\mmengine\\dataset\\base_dataset.py:298\u001b[0m, in \u001b[0;36mBaseDataset.full_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# load data information\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# filter illegal data, such as data that has no annotations.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_data()\n",
      "File \u001b[1;32md:\\pose_prediction\\data_agent\\Video_Understanding\\mmaction2\\mmaction\\datasets\\pose_dataset.py:66\u001b[0m, in \u001b[0;36mPoseDataset.load_data_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m data_list \u001b[38;5;241m=\u001b[39m mmengine\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mann_file)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     split, annos \u001b[38;5;241m=\u001b[39m \u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, data_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     67\u001b[0m     identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m annos[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_dir\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(split[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'split'"
     ]
    }
   ],
   "source": [
    "%run tools/test.py configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_gym-keypoint.py \\\n",
    "    checkpoints/slowonly_r50_8xb16-u48-240e_gym-keypoint_20220815-da338c58.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
