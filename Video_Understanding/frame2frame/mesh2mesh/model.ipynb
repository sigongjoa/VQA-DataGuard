{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame_i batch shape: torch.Size([4, 6890, 3])\n",
      "Frame_j batch shape: torch.Size([4, 6890, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class MeshDataset(Dataset):\n",
    "    def __init__(self, mesh_data, pairs=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mesh_data (np.ndarray): (859, 6890, 3) shape의 numpy 배열.\n",
    "            pairs (list of tuple): 각 tuple이 (i, j) 인덱스 pair. 기본값은 연속된 frame pair.\n",
    "        \"\"\"\n",
    "        self.mesh_data = mesh_data\n",
    "        if pairs is None:\n",
    "            # 기본적으로 연속된 frame pair (0,1), (1,2), ..., (857,858)를 사용\n",
    "            self.pairs = [(i, i+1) for i in range(mesh_data.shape[0]-1)]\n",
    "        else:\n",
    "            self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        frame_i = self.mesh_data[i]  # shape: (6890, 3)\n",
    "        frame_j = self.mesh_data[j]  # shape: (6890, 3)\n",
    "        # torch.Tensor로 변환 (필요한 경우)\n",
    "        return torch.from_numpy(frame_i).float(), torch.from_numpy(frame_j).float()\n",
    "\n",
    "# sample_data 읽기\n",
    "sample_data = np.load(\"../../../results/5 Effective Boxing Combos To Drill In_chunk2/mesh.npy\")\n",
    "\n",
    "# Dataset 생성 (원하는 pair 방식을 사용)\n",
    "dataset = MeshDataset(sample_data)\n",
    "\n",
    "# DataLoader 생성 (예: batch_size 4, shuffling)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# DataLoader 사용 예제: 한 배치에서 각 pair를 가져오기\n",
    "for batch in dataloader:\n",
    "    frames_i, frames_j = batch\n",
    "    print(\"Frame_i batch shape:\", frames_i.shape)  # (batch_size, 6890, 3)\n",
    "    print(\"Frame_j batch shape:\", frames_j.shape)  # (batch_size, 6890, 3)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        # conv3 출력: (batch, 128, 861) → flatten하면 128*861\n",
    "        self.fc_mu = nn.Linear(128 * 861, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 861, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 6890, 3) → (batch, 3, 6890)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.conv1(x))  # (batch, 32, 3445)\n",
    "        x = F.relu(self.conv2(x))  # (batch, 64, 1722)\n",
    "        x = F.relu(self.conv3(x))  # (batch, 128, 861)\n",
    "        x = x.view(x.size(0), -1)  # (batch, 128*861)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        # latent_dim → 128*861\n",
    "        self.fc = nn.Linear(latent_dim, 128 * 861)\n",
    "        # deconv1: (batch, 128, 861) → (batch, 64, 1722)\n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
    "        # deconv2: (batch, 64, 1722) → (batch, 32, 3445) with output_padding=1\n",
    "        self.deconv2 = nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1, output_padding=1)\n",
    "        # deconv3: (batch, 32, 3445) → (batch, 3, 6890)\n",
    "        self.deconv3 = nn.ConvTranspose1d(in_channels=32, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # z: (batch, latent_dim)\n",
    "        x = self.fc(z)  # (batch, 128*861)\n",
    "        x = x.view(x.size(0), 128, 861)  # (batch, 128, 861)\n",
    "        x = F.relu(self.deconv1(x))       # (batch, 64, 1722)\n",
    "        x = F.relu(self.deconv2(x))       # (batch, 32, 3445)\n",
    "        x = self.deconv3(x)               # (batch, 3, 6890)\n",
    "        x = x.permute(0, 2, 1)            # (batch, 6890, 3)\n",
    "        return x\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder(latent_dim=latent_dim)\n",
    "        self.decoder = ConvDecoder(latent_dim=latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    # 재구성 손실 (MSE)와 KL divergence 계산 (배치당 평균)\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum') / x.size(0)\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    return recon_loss + kl_div, recon_loss, kl_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Loss: nan\n",
      "Epoch [2/10] - Loss: nan\n",
      "Epoch [3/10] - Loss: nan\n",
      "Epoch [4/10] - Loss: nan\n",
      "Epoch [5/10] - Loss: nan\n",
      "Epoch [6/10] - Loss: nan\n",
      "Epoch [7/10] - Loss: nan\n",
      "Epoch [8/10] - Loss: nan\n",
      "Epoch [9/10] - Loss: nan\n",
      "Epoch [10/10] - Loss: nan\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 64\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "vae = ConvVAE(latent_dim=latent_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    vae.train()\n",
    "    total_loss = 0.0\n",
    "    for frames_i, frames_j in dataloader:\n",
    "        # 예시로 frames_i 사용 (shape: (batch, 6890, 3))\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, mu, logvar = vae(frames_i)\n",
    "        loss, recon_loss, kl_div = vae_loss(x_hat, frames_i, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * frames_i.size(0)\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "mmaction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
